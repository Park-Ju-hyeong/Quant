{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pd.read_csv(\"/Users/jooh8/Documents/GitHub/Quant/data/A000660/Index_A000660.txt\", sep=\" \", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5615"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in range(10):\n",
    "    \n",
    "    read_csv[\"고가_{}\".format(period)] = read_csv[\"고가\"].shift(periods=period).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in range(10):\n",
    "    \n",
    "    read_csv[\"최고가_{}\".format(period)] = read_csv[[\"고가_{}\".format(i) for i in range(period + 1)]].apply(np.max, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for period in range(10):\n",
    "    \n",
    "    read_csv[\"Target_{}\".format(period)] = read_csv[\"시가\"] * 1.05 < read_csv[\"고가_{}\".format(period)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(read_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Ratio_20', 'B Ratio_20', 'Aroon_20 Up', 'Down', 'Aroon Osillator_20', 'ATR_14', 'BB-RSI_종가_10', 'BB-RSI_20_2.00 상한', 'BB-RSI 하한', 'BPDL RSI_14', 'BPDL Stochatic_14', 'Chande Momentum Oscillator_10', \"Chaikin's Volatility_14,14\", 'CompuTrac Volatility_10', '+DI_14', '-DI_14', 'ADX_14', 'ADXR_14', '+DI(simple)_14', '-DI(simple)_14', 'ADX(simple)_14,14', 'ADXR(simple)_14,14,14', 'Energy+_14', 'Energy-_14', 'High Low Envelope_1', 'High Low Oscillator_3', 'Inertia_20,14,10', 'Klinger Oscillator', 'Linear Trend Oscillator_10,20', 'LRS_종가,14', 'Mass Index_20,9', 'Morris Mixed Momentum', 'New BPDL HiLo Index MA_14,7', 'Open Difference_15', 'QStick_14', 'Random Walk Index_15,3', 'RCI_5', 'RCI_9', 'RCI_13', 'RCI_18', 'Relative Volatility Index_단순,14,10', 'Reverse 단기_12', ' 장기_24', 'RSI_종가,14', 'RSI(simple)_종가,14', 'Sigma_종가,20', 'SMI_5,3,3', 'Standard Deviation_14,2.00', 'Standard Error_종가,14', 'Fast %K_5', 'Fast %D_3', 'Slow %K_5,3', 'Slow %D_3', 'Slow(Simple) %K_5,3', 'Slow(Simple) %D_3', 'StochOsc_5,3', 'TRIX기울기_종가,14', 'True Range', 'TSF Oscillator_종가,14,28', 'VHF_14', 'CCI_14']\n"
     ]
    }
   ],
   "source": [
    "momentums = columns[11:-30]\n",
    "print(momentums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Target_0', 'Target_1', 'Target_2', 'Target_3', 'Target_4', 'Target_5', 'Target_6', 'Target_7', 'Target_8', 'Target_9']\n"
     ]
    }
   ],
   "source": [
    "targets = columns[-10:]\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = read_csv[-2000:-100][momentums]\n",
    "Y_train = read_csv[-2000:-100][targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_0     32\n",
       "Target_1     71\n",
       "Target_2    188\n",
       "Target_3    281\n",
       "Target_4    344\n",
       "Target_5    365\n",
       "Target_6    401\n",
       "Target_7    407\n",
       "Target_8    436\n",
       "Target_9    456\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.apply(np.sum, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = read_csv[-100:][momentums]\n",
    "Y_test = read_csv[-100:][targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_0     2\n",
       "Target_1     2\n",
       "Target_2    11\n",
       "Target_3    17\n",
       "Target_4    24\n",
       "Target_5    21\n",
       "Target_6    21\n",
       "Target_7    23\n",
       "Target_8    21\n",
       "Target_9    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.apply(np.sum, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jooh8\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=1, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jooh8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_target_forest.fit(scaler.transform(X_train), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jooh8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "predict = multi_target_forest.predict(scaler.transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jooh8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid broadcasting comparison [array([[False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False,  True,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False,  True,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False, False, False,  True,  True,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False,  True,\n         True],\n       [False, False, False,  True,  True,  True, False, False, False,\n         True],\n       [False, False, False, False, False,  True,  True, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False, False,  True,  True,  True,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False,  True,  True, False, False,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True]])] with block values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-35695467783f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1625\u001b[0m             res = self._combine_const(other, func,\n\u001b[0;32m   1626\u001b[0m                                       \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1627\u001b[1;33m                                       try_cast=False)\n\u001b[0m\u001b[0;32m   1628\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_combine_const\u001b[1;34m(self, other, func, errors, try_cast)\u001b[0m\n\u001b[0;32m   4777\u001b[0m         new_data = self._data.eval(func=func, other=other,\n\u001b[0;32m   4778\u001b[0m                                    \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4779\u001b[1;33m                                    try_cast=try_cast)\n\u001b[0m\u001b[0;32m   4780\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   3685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3686\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3687\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, func, other, errors, try_cast, mgr)\u001b[0m\n\u001b[0;32m   1432\u001b[0m                     raise ValueError(\n\u001b[0;32m   1433\u001b[0m                         \u001b[1;34m'Invalid broadcasting comparison [{other!r}] with '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1434\u001b[1;33m                         'block values'.format(other=other))\n\u001b[0m\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m                 raise TypeError('Could not compare [{other!r}] '\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid broadcasting comparison [array([[False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False,  True,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False,  True,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False, False, False,  True,  True,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False,  True,\n         True],\n       [False, False, False,  True,  True,  True, False, False, False,\n         True],\n       [False, False, False, False, False,  True,  True, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False, False,  True,  True,  True,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False, False, False,\n         True],\n       [False, False, False,  True,  True, False, False,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False,  True,  True,  True,  True,  True,  True,\n         True],\n       [False, False, False, False, False,  True,  True,  True,  True,\n         True]])] with block values"
     ]
    }
   ],
   "source": [
    "corr = predict == Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_0    0.00\n",
       "Target_1    0.00\n",
       "Target_2    0.00\n",
       "Target_3    0.13\n",
       "Target_4    0.15\n",
       "Target_5    0.16\n",
       "Target_6    0.16\n",
       "Target_7    0.20\n",
       "Target_8    0.20\n",
       "Target_9    0.26\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.apply(np.mean, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.126"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(corr.apply(np.mean, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTarget_0    0.997895\\nTarget_1    0.990000\\nTarget_2    0.964211\\nTarget_3    0.944737\\nTarget_4    0.931579\\nTarget_5    0.931579\\nTarget_6    0.927895\\nTarget_7    0.933684\\nTarget_8    0.935789\\nTarget_9    0.933684\\ndtype: float64\\n0.9491052631578947\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Target_0    0.997895\n",
    "Target_1    0.990000\n",
    "Target_2    0.964211\n",
    "Target_3    0.944737\n",
    "Target_4    0.931579\n",
    "Target_5    0.931579\n",
    "Target_6    0.927895\n",
    "Target_7    0.933684\n",
    "Target_8    0.935789\n",
    "Target_9    0.933684\n",
    "dtype: float64\n",
    "0.9491052631578947\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jooh8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "predict = multi_target_forest.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = predict == Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_0    0.00\n",
       "Target_1    0.00\n",
       "Target_2    0.00\n",
       "Target_3    0.13\n",
       "Target_4    0.15\n",
       "Target_5    0.16\n",
       "Target_6    0.16\n",
       "Target_7    0.20\n",
       "Target_8    0.20\n",
       "Target_9    0.26\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.apply(np.mean, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.126"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(corr.apply(np.mean, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTarget_0    1.00\\nTarget_1    1.00\\nTarget_2    0.95\\nTarget_3    0.89\\nTarget_4    0.91\\nTarget_5    0.92\\nTarget_6    0.95\\nTarget_7    0.95\\nTarget_8    0.92\\nTarget_9    0.92\\ndtype: float64\\n0.9410000000000001\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Target_0    1.00\n",
    "Target_1    1.00\n",
    "Target_2    0.95\n",
    "Target_3    0.89\n",
    "Target_4    0.91\n",
    "Target_5    0.92\n",
    "Target_6    0.95\n",
    "Target_7    0.95\n",
    "Target_8    0.92\n",
    "Target_9    0.92\n",
    "dtype: float64\n",
    "0.9410000000000001\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
